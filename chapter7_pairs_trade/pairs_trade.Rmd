---
title: "Portfolio Theory: Chapter 7 (The Pairs Trade)"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Authors: [GitHub Contributors](https://github.com/Matt-Brigida/portfolio-theory/graphs/contributors)

The pairs trade is a classic example of a statistical arbitrage (stat arb) strategy---its history dates back to the 1980s.  

This strategy can be thought of as the opposite of Markowitz mean/variance optimization.  In Markowitz we diversified efficiently, which reduces firm specific risk but leaves market risk in our portfolio.  In the pairs trade, we'll remove market risk, and hold only firm-specific risk. Thus, the pairs trade is known as a 'market-neutral' strategy. 

The strategy is a loose application of the **law of one price**.  The law of one price says that if two securities have the same payoff in all states of the world, then the two securities must have the same price.  This is enforced by arbitrage.  Say the price of security $A$ is greater than $B$, and they have the same payoff.  Then you could sell $A$ and buy $B$, earning $A-B$, and the payoffs (being the same) will net to $0$.  

Of course, two stocks will not have the same payoff in all states of the world---hence the term 'loose application'.  We hope to find two stocks whose payoffs are fairly similar in all states of the world.  

For example, say we find two firms solely focus on crude oil exploration and production in the Bakken shale in North Dakota. These two firms produce identical commodities in the same place, and sell the commodity to the same market.  These two firms' payoffs should be similar functions of a common set of inputs: price of crude oil; cost of drilling; cost of mineral rights; etc.



## Implementation

There is no single way to implement the pairs trade. This is an active area of research, and provides you with a venue to create your own strategy (and become wealthy if it works).  However, to learn we'll implement the strategy outlined in Gatev et al ().  


To implement the pairs trade we'll first define what is normal behavior for a particular pair.  We do this over the 'estimation period'.  Once the behavior is defined, we wait for the pair to behave abnormally over the trading period.  Note, the trading period is after the estimation period, and the two periods do not overlap.  

The app below will give you the two parameters with which we define behavior for a particular pair and estimation periods which you input.  

# Estimation Period

```{r, messsage=FALSE, warning=FALSE, echo = FALSE}
#{{{
## in the process of translating this code into a Shiny app
## just run for each pair?

inputPanel(
  dateRangeInput("estim_period", "Estimation Period", start = "2015-09-01", end = "2015-12-31"),
  ## selectizeInput(tickers, "Enter Tickers", )
  textInput("ticker1", "First Stock Ticker", value = "XOM"),
  textInput("ticker2", "Second Stock Ticker", value = "COP")
)

renderPrint({
    
library(quantmod)
## Estimation period
from <- input$estim_period[1]
to <- input$estim_period[2]

## The code below to calculate an xts object of returns is from an SO or Quant.SE post.  I need to find it and cite.
env <- new.env()
Symbols <- c(input$ticker1, input$ticker2)
getSymbols(Symbols = Symbols, env = env, from = from, to = to)
args <- eapply(env = env, FUN = function(x){ClCl(x)})[Symbols]
returns <- na.omit(do.call(what = merge, args = args))
colnames(returns) <- Symbols
## convert reutrns to  normalized prices
norm.prices <<- cumsum(returns)

norm.prices.df <- as.data.frame(norm.prices)
## function to find the average squared deviation of the normalized prices for two stocks
  
    ## Calculate the emtimation period parameters (the average squared deviation and the standard deviation of the squared deviations):
    asd.e <<- mean(( norm.prices.df[,1] - norm.prices.df[,2])^2 )
    ssd.e <<- sd(( norm.prices.df[,1] - norm.prices.df[,2])^2 )
    cat("The average squared deviation is", asd.e ,"\n")
    cat("The standard deviation of the squared deviations is:", ssd.e ,"\n")
## }

## run this function by typing g() into the interpreter and it will create
## a .csv file in your working directory with all the pairs and their
## avg squared dev and stdev of squared deviation sorted from lowest
#  avg sq dev to highest

## g <- function(){
## list <- matrix(0,nrow=dim(norm.prices.df)[2], ncol=dim(norm.prices.df)[2])
## asds <- matrix(0,nrow=dim(norm.prices.df)[2], ncol=dim(norm.prices.df)[2])
## asstdevs <- matrix(0,nrow=dim(norm.prices.df)[2], ncol=dim(norm.prices.df)[2])
## for(i in 1:dim(norm.prices.df)[2]){
##     for(j in 1:dim(norm.prices.df)[2]){
##         list[i,j] <- as.character(paste(names(norm.prices.df)[i],names(norm.prices.df)[j]),sep="")
##         asds[i,j] <- mean((norm.prices.df[,i]-norm.prices.df[,j])^2)
##         asstdevs[i,j] <- sd((norm.prices.df[,i]-norm.prices.df[,j])^2)
##           }
##     }

})
#}}}
```

### What does a good pair look like?

You want pairs whose normalized prices (cumulative returns) stay close and repeatedly cross. What you do *not* want is a pair where the difference between the prices tends to grow as if there is nothing holding the prices together.  

Take a look at Exxon (XOM) and Conoco Phillips (COP) below.  This is a fairly good pair---if they diverge they tend to converge again later.  Note, this pair makes sense from an economic standpoint. We are looking for companies which are similar.  Now replace Exxon with 3D Systems (DDD).  Note the normalized prices don't seem to behave similarly. Also, the companies are very different (3D printing and major oil integrated oil and gas firm).  So there is no reason **a priori** for them to behave similarly.  

In short, think about walking a dog on a leash.  You and the dog will be a bit apart, and then the dig may run to the other side, and you'll cross.  You'll never get too far apart given the leash.  This is a good pair.  

The normalized prices for the pair you have entered above is charted below.  Use this to help you choose pairs.  

```{r echo=FALSE}
library(dygraphs)
renderDygraph({
 update <- input$ticker1
 dygraph(norm.prices) 
  
})
```


# Trading Period

Given the behavior of the pair estimated above, we can then define periods in which the pair is behaving 'abnormally'.  During these abnormal periods we bet that the pair will again return to its normal bevavior. 

Specifically, we'll monitor how many standard deviations the squared deviation is from its average squared deviation.  When the squared deviation deviated from its average by a threhold number of shandard deviations, we'll initiate a pairs trade.  We'll close the pairs trade when the squared deviation drops below another threshold number of standard deviations.

### Thresholds

It is for you to determine the thresholds at which you open and close your pairs trade.  You can take a look at what others have done, however there is no theoretical reason why the threshold should be 2 instead of 2.1.  You can, of course, run different thresholds over historical data and see what was optimal.  A decent place to start is:
- Open the trade when the pair's squared deviation is 2 standard deviations above its average.
- Close the trade when the pair's squared deviation goes to 0.

### Opening/Closing Trades

When the squared deviation goes above our threshold we then open a pairs trade.  This means we buy one stock and short another.  Two questions immediately come to mind, (1) which stock do be buy and which do we sell and (2) how much of each stock to buy and sell?

#### Stock to buy/sell




```{r echo = FALSE}
renderDygraph({
from.t <- input$estim_period[2] + 1
to.t <- Sys.Date()

## The code below to calculate an xts object of returns is from an SO or Quant.SE post.  I need to find it and cite.
env.t <- new.env()
Symbols <- c(input$ticker1, input$ticker2)
getSymbols(Symbols = Symbols, env = env.t, from = from.t, to = to.t)
args <- eapply(env = env.t, FUN = function(x){ClCl(x)})[Symbols]
returns.t <- na.omit(do.call(what = merge, args = args))
colnames(returns.t) <- Symbols
## convert reutrns to  normalized prices
norm.prices.t <- cumsum(returns.t)## ll <- dim(norm.prices.df)[2]

numSD <- ( (norm.prices.t[,1] - norm.prices.t[,2])^2 - asd.e ) / ssd.e

## nope
## signal <- numSD
## signal[signal < 0] <- 1
## signal[signal > 0 & signal < 2] <- 0
## signal[signal > 2] <- 2
trade <- rep(0, length(seq_along(numSD)))
for (i in 2:length(seq_along(numSD))) {
    if (numSD[i] > 2 && numSD[i-1] < 2) {
        trade[i] <- 1
    } else {
        if (numSD[i] < 0 && numSD[i-1] > 0) {
            trade <- -1
        } else {
            trade[i] <- 0
        }
    }
}

cumTrade <- cumsum(trade)


dygraph( as.xts(trade, order.by = index(numSD)) , main = paste0(colnames(returns.t)[1], " & ", colnames(returns.t)[2]), ylab = "# Standard Deviations")
})
```

<!--- end -->

#### Why can there be such large deviation from the average?

For some pairs we'll see a the average aquared deviation during the trading periods is more than 30 standard deviation from the average during the estimation period.  This seems very unlikely given Chebychev's inequality.
