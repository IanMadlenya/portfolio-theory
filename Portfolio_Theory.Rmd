---
title: "Portfolio Theory"
author: "Matt Brigida"
date: "November 27, 2015"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!---
Note, much of the R code in this text was written long ago, when I wrote even worse R code than I do now.  The code works, but it is inefficient and ugly.  I decided not to rewrite it however, feeling it more important to get the text out and into students' hands.  If you can improve the code, please feel free.  Pull requests are always welcome.
-->


# Introduction

Despite 'theory' in the title, this course will teach you how to construct portfolios in the real world.  In fact, some of the most interesting topics in this course will be on how to implement the theories we have learned.  

Through this course the student will gain a working knowledge of what we mean by the term *risk* in finance.  There will be differing measures of risk depending on the assumptions you make about the world.  Then, for a given set of assumptions, risk will directly determine portfolio allocations.  We'll also cover an extension of this, where the resulting portfolio allocations will imply an equilibrium expected return for each asset (the CAPM).  An apt alternative title for this course would be 'Risk and its Implications'. 


## Risk and Return without Theory

Mosts texts in portfolio theory start with a chart of the rate of return on different asset classes over time.  We'll be no different. However, take care to note the point of this exercise is simply to get an intuitive feel of the idea that taking more risk grants a higher return.



### Ergodic Time Series

You may point out that what we have just done is not really compelling evidence. We have looked at an historical sample of size 1, and implied that this must hold.  In fact, to make any sort of statement about the empirical relationship between risk and return we would need to sample many times from all possible histories, and then average over these histories.  Of course, we can only ever observe one history---an important distinction from empirical results in disciplines such as physics and chemistry.

So we make the assumption that time series in finance are ergodic.  This means we assume that averaging over time gives the same result as averaging over possible histories. Note, this is an (necessary) assumption; both untestable and somewhat unreasonable. So view results with appropriate caution.

Later, however we'll also see theories which imply a similar risk/return relationship. This will lend credence to these earlier empirical diversions.  

### How good of an approximation is the normal distribution?

```{r comparetoNormal, echo=FALSE}
## compare normal and empirical distributions 

inputPanel(
  textInput("ticker1", "Stock Ticker", value = "GE"),
  dateInput("startDate1", "Start Date", value = "2015-01-01")
)

renderPlot({
library(tseries)
library(quantmod)
  
    x <- get.hist.quote(input$ticker1, start = input$startDate1, quote = "Close")
    x <- xts(x)
    r <- Delt(x, type = 'log')[-1]

    plot(density(r), main = "Normal versus Empirical Distribution", lty = 1, 
        col = 1, lwd = 2, xlab = "Log-Returns in %/100") #, sub = "Matthew Brigida; Clarion UofP")

    lines(density(rnorm(5e+05, mean = mean(r), sd = sd(r))), lty = 4, col = 2, 
        lwd = 2)

    legend("topright", c("Stock Return Density", "Normal Density"), col = c(1, 2), 
        lty = c(1, 4), lwd = c(2, 2))

    # cat("The sample skewness is", skewness(r), "\n")
    # cat("For a t-statistic of", skewness(r)/(sqrt(6/length(r))), "\n")
    # p1 <- 2 * (1 - pt(abs(skewness(r)/(sqrt(6/length(r)))), length(r) - 1))
    # cat("And a p-value of", p1, "\n")
    # cat("So we", ifelse(p1 < 0.05, "reject the null, and find the distribution is skewed.", 
    #     "do not reject the null, the distribution is symmetric."), "\n")
    # cat("\n")
    # 
    # cat("The sample excess kurtosis is", kurtosis(r)[1], "\n")
    # cat("For a t-statistic of", kurtosis(r)/(sqrt(24/length(r))), "\n")
    # p2 <- 2 * (1 - pt(abs(kurtosis(r)/(sqrt(24/length(r)))), length(r) - 1))
    # cat("And a p-value of", p2, "\n")
    # cat("So we", ifelse(p2 < 0.05, "reject the null, and find the distribution has fat tails.", 
    #     "do not reject the null, the distribution does not have fat tails."), 
    #     "\n")
    # cat("\n")
})    
```


<br/>
<br/>
<br/>
<br/>



Portfolio Frontier with Two Risky Assets and Varying Correlation
=========================================================================

The following widget shows the efficient frontier for a portfolio of two risky assets.  The first risky asset (call it 'Debt') has a 9\% expected return and 11\% standard deviation.  The second portfolio (call it 'Equity') has a 12\% expected return and a 20\% standard deviation.  You are free to change the correlation coefficient between Debt and Equiry returns, and see the resulting effect on the efficient frontier.

What you should note, is that as you lower the correlation coefficient, you can receive the same expected return for less risk.  That is, investors benefit form the lower correlation.  If the correlation coefficient is -1, then you can construct a risk-free portfolio.  See below for the calculation.    


```{r, echo = FALSE}
inputPanel({
    sliderInput("correl", "Correlation Coefficient", min = -1, max = 1, step = 0.01, value = 0.5, animate = TRUE)
})

renderPlot({
    ## library(ggvis)
    
    w.e <- seq(-.5,1.5, by=.01)
    w.d <- 1 - w.e
    r.e <- .12
    r.d <- .09
    E <- w.e*r.e+w.d*r.d
    s.e <- .2
    s.d <- .11
    S <- sqrt((w.e^2)*s.e^2+(w.d^2)*s.d^2+2*w.d*w.e*s.e*s.d*input$correl)
    dataEff <- data.frame(cbind(S,E,w.e))
    ## plot(S, E, type='l', xlim=c(0,.3), xlab='Portfolio Standard Deviation', ylab='Portfolio Expected Return', col = 'green')
    S.ports <- c(dataEff[dataEff$w.e == 0, ]$S, dataEff[dataEff$w.e == 1, ]$S)
    E.ports <- c(dataEff[dataEff$w.e == 0, ]$E, dataEff[dataEff$w.e == 1, ]$E)
    dataPorts <- cbind(S.ports, E.ports)
    plot(dataPorts, type='p', xlim=c(0,.3), xlab='Portfolio Standard Deviation', ylab='Portfolio Expected Return', col = 'black', ylim = c(.08, .13))
    lines(S, E, col = "green", lwd = 1.5)
    text(dataPorts, labels = c("Debt", "Equity"), cex = 1, pos = 2)

## ggvis attempt -- all looks good except for overlapping legend.    
##     effFront <- cbind(E,S, w.e)
##     effFront <- data.frame(effFront)
##     asset <- 0
##     for(i in 1:dim(effFront)[1]){
##         if(effFront$w.e[i] == 1){
##         asset[i] = "Equity" 
##     } else {
##         if(effFront$w.e[i] == 0){
##             asset[i] = "Debt" 
##         } else {
##             asset[i] = "Combined"
##         }
##     }
##     }

##     size.pt <- 0
##     for(i in 1:dim(effFront)[1]){
##         if(effFront$w.e[i] == 1){
##         size.pt[i] = 5
##     } else {
##         if(effFront$w.e[i] == 0){
##             size.pt[i] = 5 
##         } else {
##             size.pt[i] = 1
##         }
##     }
##     }
    
## effFront <- cbind(effFront, asset, size.pt)
## p <- effFront %>% ggvis(~S, ~E, size = ~size.pt) %>% layer_points(fill = ~factor(asset)) #%>% add_legend(c("fill", "size"))

##     p %>% scale_numeric("size", domain = c("Equity", "Debt", "Combined"), range = c(7, 7, 1))
})
## f <- seq(-1, 1, by = .1)
## S2 <- matrix(0, nrow=201, ncol=21)
## for (i in 1:21){Sys.sleep(.5)
##   S2[,i] <- sqrt((w.e^2)*s.e^2+(w.d^2)*s.d^2+2*w.d*w.e*s.e*s.d*f[i])
##   lines(S2[,i], E, col=i, lwd=2)}
```

You can see if you set the coefficient to -1, then the efficient frontier has a point with no risk, and some expected return.  To calculate the expected return at that point, we first need to calculate the asset weights on the portfolio with no risk.

#### Question:  Can the risk-free rate above be different from the risk-free rate on Treasury securities?  



























Testing for Portfolio Alpha
========================================================



```{r, message=FALSE,warning=FALSE, cache=TRUE}
library(quantmod)
env <- new.env()
Symbols <- c('SPY', 'QQQ', 'XLF', 'TLT','IBM','AAPL','XOM','BP','DDD')
getSymbols(Symbols = Symbols, env = env, from = '2013-01-01')
args <- eapply(env = env, FUN = function(x){ClCl(x)})[Symbols]
returns <- na.omit(do.call(what = merge, args = args))
colnames(returns) <- Symbols

## the basis for the code above is from the stackoverflow post here: (need to find and cite, note it might be quant.SE)

srets <- as.matrix(returns)
X <- cbind(1,srets[,1])
alpha <- 0
beta <- 0

for (i in 1:dim(srets)[2]) {
alpha[i] <- (solve(t(X) %*% X) %*% t(X) %*% srets[1:(dim(srets)[1]),i])[1]
beta[i] <- (solve(t(X) %*% X) %*% t(X) %*% srets[1:(dim(srets)[1]),i])[2]}

t.test(alpha)

plot(density(alpha), main = "Empirical Density Function", xlab = "alpha")

ab <- rbind(alpha,beta)

ab <- as.data.frame(ab)

names(ab) <- Symbols

attach(ab)

t.test(alpha[beta > 1],alpha[beta < 1])
```
